import joblib
import json

import numpy as np
import pandas as pd
from sklearn.utils import resample
from sklearn.preprocessing import Normalizer
from sklearn.feature_extraction.text import TfidfVectorizer

def preprocess_data(data):

    """
    Preprocesses the data by cleaning it and preparing it for the machine learning model.

    """

    # convert the data to a pandas dataframe
    data = pd.DataFrame([data])

    # drop duplicates
    df = data.drop_duplicates()
    
    # reset index
    df = df.reset_index(drop=True)

    # remove non numerical columns
    data1 = df.drop(['Name', 'Opcodes', 'DLLImports'], axis=1)

    # keep non-numeric columns for processing
    data2 = df[['Opcodes', 'DLLImports']]

    # replace nan with empty string
    data2 = data2.fillna('')

    # load the tf-idf vectorizers
    vectorizer_dllimports = joblib.load('./src/models/vectorizer_dllimports.pkl')
    vectorizer_opcodes = joblib.load('./src/models/vectorizer_opcodes.pkl')

    # transform the text data using the tf-idf vectorizers
    dllimportsTFIDF = vectorizer_dllimports.transform(data2['DLLImports'])
    opcodesTFIDF = vectorizer_opcodes.transform(data2['Opcodes'])

    # combine the two vectors into one
    combinedTFIDF = np.concatenate([dllimportsTFIDF.toarray(), opcodesTFIDF.toarray()], axis=1)

    # normalize the combined vectors to have unit norm
    normalizer = Normalizer()
    combinedTFIDF = normalizer.fit_transform(combinedTFIDF)

    # create a dataframe from the combined vectors to save to csv
    features = vectorizer_dllimports.get_feature_names_out().tolist() + vectorizer_opcodes.get_feature_names_out().tolist()
    data2 = pd.DataFrame(combinedTFIDF, columns=features)

    # combine the converted text data with the numerical data
    data = pd.concat([data1, data2], axis=1)
    data.reset_index(drop=True, inplace=True)

    # feature selection
    features = joblib.load('./src/models/important_features.pkl')

    # select only the important features
    data = data[features]

    # load the scaler
    scaler = joblib.load('./src/models/scaler.pkl')

    # scale the data
    data = scaler.transform(data)

    return data


def predict(data):
    
    """
    Predicts the class of the data using the machine learning model.

    """

    # convert the data to a pandas dataframe
    data = pd.DataFrame(data)

    # load the machine learning model
    model = joblib.load('./src/models/random_forest_model.pkl')

    # predict the class of the data
    prediction = model.predict(data)[0]
    confidence = model.predict_proba(data)

    return {'prediction': prediction, 'confidence': round(max(confidence[0]) * 100, 2)}
